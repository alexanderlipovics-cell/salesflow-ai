# ðŸ§  AI-Architektur Analyse & Optimierung

## ðŸ“Š Collective Intelligence System

### Architektur-Ãœbersicht

Das System basiert auf einer **4-Ebenen-Architektur** (Non Plus Ultra):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EBENE 4: BEREITSTELLUNG (RAG + Inferenz + Styling)        â”‚
â”‚ - Knowledge Graph Service                                   â”‚
â”‚ - RAG Retrieval                                             â”‚
â”‚ - User Profile Styling                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ EBENE 3: GLOBALES MODELL (W_Global via Self-Hosted LLM)     â”‚
â”‚ - Groq API (llama-3.1-8b-instant) - ULTRA-SCHNELL         â”‚
â”‚ - Ollama (lokales Fallback)                                 â”‚
â”‚ - vLLM (High-Performance Server)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ EBENE 2: GENERALISIERUNG (RLHF + Differential Privacy)    â”‚
â”‚ - RLHF Feedback Sessions                                    â”‚
â”‚ - Training Data Pool (anonymisiert)                         â”‚
â”‚ - Privacy Audit Log                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ EBENE 1: LOKAL (D_User Profile, Session Cache)            â”‚
â”‚ - User Learning Profile                                     â”‚
â”‚ - User Session Cache                                        â”‚
â”‚ - Top Script IDs                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Formel:** `Antwort = LLM(W_Global | Prompt + RAG_Context + D_User)`

---

## ðŸ”„ Datenfluss

### 1. Chat-Nachricht â†’ AI Response

```
User Input
    â†“
[Intent Detection] â†’ gpt-4o-mini (schnell)
    â†“
[Model Router] â†’ gpt-4o-mini (CONTENT/SIMPLE) oder gpt-4o (COMPLEX)
    â†“
[System Prompt] â†’ CAS_SYSTEM + SALES_PSYCHOLOGY + User Context
    â†“
[OpenAI API] â†’ call_openai_with_fallback()
    â†“
[Tool Execution] â†’ create_lead, write_message, etc.
    â†“
[Cost Tracking] â†’ ai_usage Tabelle
    â†“
[Response] â†’ User
```

**Datenbank-Tabellen:**
- `ai_chat_messages` - Chat-Historie
- `ai_usage` - Token-Usage & Kosten
- `user_learning_profile` - User-spezifische PrÃ¤ferenzen

---

### 2. Lead erstellen â†’ Follow-up & Learning

```
User: "Erstelle Lead fÃ¼r Max Mustermann"
    â†“
[Tool: create_lead] â†’ leads Tabelle
    â†“
[Auto Follow-up] â†’ followup_suggestions Tabelle (3 Tage spÃ¤ter)
    â†“
[Suggested Actions] â†’ prepare_message, research_company
    â†“
[Response] â†’ User
```

**Datenbank-Tabellen:**
- `leads` - Lead-Daten
- `followup_suggestions` - Auto-Follow-ups
- `activities` - Activity Log

---

### 3. Nachricht generieren â†’ Collective Intelligence

```
User: "Schreibe Nachricht fÃ¼r Lead X"
    â†“
[Collective Intelligence Engine]
    â”œâ”€â†’ [User Profile laden] â†’ D_User (Ebene 1)
    â”œâ”€â†’ [RAG Search] â†’ Knowledge Graph (Ebene 3)
    â”œâ”€â†’ [System Prompt] â†’ D_User Styling + RAG Context
    â””â”€â†’ [LLM Generation] â†’ Groq/Ollama (W_Global)
    â†“
[RLHF Session] â†’ rlhf_feedback_sessions (Ebene 2)
    â†“
[Response] â†’ User
```

**Datenbank-Tabellen:**
- `user_learning_profile` - User-PrÃ¤ferenzen (Tone, Emoji, LÃ¤nge)
- `knowledge_graph_nodes` - Erfolgreiche Scripts/Strategien
- `rlhf_feedback_sessions` - RLHF Feedback Loop
- `rag_retrieval_log` - RAG Retrieval Tracking

---

### 4. Erfolg loggen (Conversion) â†’ Learning Loop

```
User: "Lead konvertiert" / "Deal gewonnen"
    â†“
[record_feedback] â†’ rlhf_feedback_sessions
    â”œâ”€â†’ outcome: "converted"
    â”œâ”€â†’ response_used: true
    â””â”€â†’ user_rating: optional
    â†“
[User Learning Service]
    â”œâ”€â†’ analyze_conversions() â†’ Pattern-Extraktion
    â”œâ”€â†’ update_profile_from_conversions() â†’ User Profile Update
    â””â”€â†’ Channel/Length/Emoji/Tone Insights
    â†“
[Training Data Pool] â†’ aggregate_training_data()
    â”œâ”€â†’ Differential Privacy (Laplace Noise)
    â””â”€â†’ training_data_pool Tabelle
    â†“
[Knowledge Graph] â†’ Erfolgreiche Patterns als Nodes
    â†“
[W_Global] â†’ NÃ¤chste Generation nutzt gelerntes Wissen
```

**Datenbank-Tabellen:**
- `rlhf_feedback_sessions` - Conversion Events
- `user_learning_profile` - Aktualisierte PrÃ¤ferenzen
- `training_data_pool` - Anonymisierte Trainings-Daten
- `knowledge_graph_nodes` - Erfolgreiche Scripts/Strategien

---

## ðŸ’¾ Lokales Wissen

### Tabellen & Speicherung

#### Ebene 1: User-spezifisch
- **`user_learning_profile`**
  - `preferred_tone` - "direct", "soft", "professional", etc.
  - `avg_message_length` - Durchschnittliche NachrichtenlÃ¤nge
  - `emoji_usage_level` - 0-5
  - `formality_score` - 0.0-1.0
  - `sales_style` - "aggressive", "balanced", "soft"
  - `top_script_ids` - Array von erfolgreichen Script-IDs
  - `conversion_rate` - User-spezifische Conversion-Rate

#### Ebene 2: RLHF & Training
- **`rlhf_feedback_sessions`**
  - `context_hash` - Anonymisierter Context (SHA256)
  - `input_type` - "objection_response", "message_generation", etc.
  - `generated_response` - AI-generierte Antwort
  - `outcome` - "converted", "positive_reply", "negative_reply", etc.
  - `user_rating` - 1-5 (optional)
  - `user_edited` - Boolean (wurde Antwort bearbeitet?)

- **`training_data_pool`**
  - `success_rate` - Erfolgsrate (ohne Noise)
  - `noisy_success_rate` - Mit Differential Privacy
  - `privacy_epsilon` - Privacy-Parameter
  - `avg_reward_score` - Durchschnittlicher Reward

#### Ebene 3: Knowledge Graph
- **`knowledge_graph_nodes`**
  - `node_type` - "script", "strategy", "objection", "persona"
  - `embedding` - Vector Embedding (nomic-embed-text)
  - `properties` - JSONB mit Metadaten
  - `label` - Human-readable Label

- **`knowledge_graph_edges`**
  - `edge_type` - "similar_to", "used_with", "follows"
  - `weight` - Edge-Gewichtung

#### Ebene 4: RAG Logging
- **`rag_retrieval_log`**
  - `retrieved_node_ids` - Welche Nodes wurden gefunden?
  - `retrieval_scores` - Similarity Scores
  - `generation_latency_ms` - Performance-Tracking

---

## ðŸ¤– Externe LLM Calls

| Funktion | Model | Provider | Dauer | Optimierbar? | Notes |
|----------|-------|----------|-------|--------------|-------|
| **Intent Detection** | gpt-4o-mini | OpenAI | ~500ms | âœ… â†’ Groq | KÃ¶nnte zu Groq (llama-3.1-8b) |
| **Chat Response (SIMPLE)** | gpt-4o-mini | OpenAI | ~1-2s | âœ… â†’ Groq | Einfache Queries |
| **Chat Response (COMPLEX)** | gpt-4o | OpenAI | ~3-5s | âŒ | BenÃ¶tigt Tools |
| **Message Generation** | Groq/Ollama | Self-Hosted | ~1-2s | âœ… | Bereits optimiert! |
| **Objection Handling** | gpt-4o | OpenAI | ~3-5s | âš ï¸ â†’ Claude Haiku | KÃ¶nnte zu Claude Haiku |
| **Vision (Screenshots)** | claude-3-5-sonnet | Anthropic | ~2-4s | âŒ | Vision benÃ¶tigt Sonnet |
| **Receipt Scanning** | claude-3-5-sonnet | Anthropic | ~2-4s | âŒ | Vision benÃ¶tigt Sonnet |
| **Contact Parsing** | claude-sonnet-4 | Anthropic | ~2-4s | âš ï¸ â†’ Claude Haiku | KÃ¶nnte zu Haiku |
| **Collective Intelligence** | llama-3.1-8b | Groq | ~1-2s | âœ… | Bereits optimiert! |
| **Embeddings** | nomic-embed-text | Ollama | ~200ms | âœ… | Lokal, schnell |

---

## ðŸš€ Performance-Analyse

### Aktuelle Bottlenecks

1. **OpenAI Rate Limits** (429 Errors)
   - **Problem:** Zu viele Requests zu gpt-4o
   - **LÃ¶sung:** âœ… Bereits implementiert - Fallback zu gpt-4o-mini
   - **Status:** âœ… Aktiv

2. **Lange Response-Zeiten** (22-52 Sekunden)
   - **Problem:** System Prompt zu lang + alle Messages in History
   - **LÃ¶sung:** âœ… Bereits optimiert:
     - System Prompt gekÃ¼rzt (CAS_SYSTEM + SALES_PSYCHOLOGY behalten)
     - History auf 5 Messages begrenzt
   - **Status:** âœ… Aktiv

3. **Hohe Token-Kosten**
   - **Problem:** 19.000+ Tokens pro Request
   - **LÃ¶sung:** âœ… Bereits optimiert:
     - Default: gpt-4o-mini (90% der Requests)
     - Nur COMPLEX â†’ gpt-4o
   - **Status:** âœ… Aktiv

---

## ðŸŽ¯ Empfohlene Optimierungen

### 1. âœ… Bereits implementiert

- [x] Model-Routing: CONTENT/SIMPLE â†’ gpt-4o-mini
- [x] History-Begrenzung: 5 Messages
- [x] System Prompt gekÃ¼rzt
- [x] Rate Limit Fallback zu gpt-4o-mini
- [x] Collective Intelligence nutzt Groq (ultra-schnell)

### 2. ðŸ”„ Weitere Optimierungen

#### A. Intent Detection â†’ Groq
**Aktuell:** gpt-4o-mini (~500ms)  
**Optimiert:** Groq llama-3.1-8b-instant (~200ms)  
**Ersparnis:** 60% schneller, 90% gÃ¼nstiger  
**Datei:** `backend/app/ai/intent_detector.py`

```python
# Statt OpenAI:
# client.chat.completions.create(model="gpt-4o-mini", ...)

# Zu Groq:
# groq_client.chat.completions.create(model="llama-3.1-8b-instant", ...)
```

#### B. Objection Handling â†’ Claude Haiku
**Aktuell:** gpt-4o (~3-5s)  
**Optimiert:** Claude Haiku (~1-2s)  
**Ersparnis:** 50% schneller, 80% gÃ¼nstiger  
**Datei:** `backend/app/routers/objections.py`

```python
# Statt gpt-4o:
# client = AsyncOpenAI(...)

# Zu Claude Haiku:
# client = Anthropic(...)
# model = "claude-haiku-4-5-20251001"
```

#### C. Contact Parsing â†’ Claude Haiku
**Aktuell:** Claude Sonnet (~2-4s)  
**Optimiert:** Claude Haiku (~1-2s)  
**Ersparnis:** 50% schneller, 90% gÃ¼nstiger  
**Datei:** `backend/app/routers/smart_import.py`

#### D. Simple Chat Queries â†’ Groq
**Aktuell:** gpt-4o-mini (~1-2s)  
**Optimiert:** Groq llama-3.1-8b-instant (~500ms)  
**Ersparnis:** 50% schneller, 90% gÃ¼nstiger  
**Datei:** `backend/app/ai/agent.py`

**Bedingung:** Nur wenn KEINE Tools benÃ¶tigt werden!

---

## ðŸ“ˆ Was muss bei OpenAI bleiben?

### Tools-Requirement
- **`create_lead`** â†’ BenÃ¶tigt gpt-4o (Tools)
- **`write_message`** â†’ BenÃ¶tigt gpt-4o (Tools)
- **`update_lead_status`** â†’ BenÃ¶tigt gpt-4o (Tools)
- **`create_task`** â†’ BenÃ¶tigt gpt-4o (Tools)
- **`web_search`** â†’ BenÃ¶tigt gpt-4o (Tools)

**Warum?** OpenAI ist der einzige Provider mit zuverlÃ¤ssiger Tool/Function Calling UnterstÃ¼tzung.

---

## ðŸ  Was nutzt bereits lokale LLMs?

### âœ… Bereits optimiert

1. **Collective Intelligence Engine**
   - **Provider:** Groq (llama-3.1-8b-instant)
   - **Dauer:** ~1-2 Sekunden
   - **Datei:** `backend/app/services/collective_intelligence_engine.py`

2. **Embeddings fÃ¼r RAG**
   - **Provider:** Ollama (nomic-embed-text)
   - **Dauer:** ~200ms
   - **Datei:** `backend/app/services/collective_intelligence_engine.py`

3. **Knowledge Graph Search**
   - **Provider:** Lokale PostgreSQL (pgvector)
   - **Dauer:** ~50ms
   - **Datei:** `backend/app/services/collective_intelligence_engine.py`

---

## ðŸ” Bottlenecks identifiziert

### 1. System Prompt LÃ¤nge
**Status:** âœ… Optimiert (CAS_SYSTEM + SALES_PSYCHOLOGY behalten)

### 2. Conversation History
**Status:** âœ… Optimiert (5 Messages max)

### 3. OpenAI Rate Limits
**Status:** âœ… Optimiert (Fallback zu gpt-4o-mini)

### 4. Tool Execution Overhead
**Status:** âš ï¸ Nicht optimierbar (benÃ¶tigt OpenAI)

### 5. RAG Retrieval
**Status:** âœ… Optimiert (lokale pgvector)

---

## ðŸ“Š Zusammenfassung

### Aktuelle Performance
- **Durchschnittliche Response-Zeit:** 2-5 Sekunden (nach Optimierungen)
- **Token-Kosten:** ~70% reduziert (durch gpt-4o-mini)
- **Rate Limit Errors:** ~90% reduziert (durch Fallback)

### Potenzial fÃ¼r weitere Optimierungen
- **Intent Detection:** â†’ Groq (60% schneller)
- **Objection Handling:** â†’ Claude Haiku (50% schneller)
- **Contact Parsing:** â†’ Claude Haiku (50% schneller)
- **Simple Chat Queries:** â†’ Groq (50% schneller, nur wenn keine Tools)

### Was funktioniert bereits perfekt
- âœ… Collective Intelligence (Groq)
- âœ… RAG Retrieval (lokale pgvector)
- âœ… Model-Routing (Smart Routing)
- âœ… Rate Limit Fallback
- âœ… Cost Tracking

---

## ðŸŽ¯ NÃ¤chste Schritte

1. **Intent Detection zu Groq migrieren** (Quick Win)
2. **Objection Handling zu Claude Haiku** (Mittel)
3. **Contact Parsing zu Claude Haiku** (Mittel)
4. **Simple Chat Queries zu Groq** (Komplex - Tool-Detection nÃ¶tig)

**PrioritÃ¤t:** 1 > 2 > 3 > 4

