"""
Copilot-Router f√ºr FELLO - Sales AI Copilot.

Dieser Router liefert intelligente Antwort-Optionen (Soft, Direkt, Frage)
basierend auf der Nutzeranfrage und dem Kontext.
"""

from __future__ import annotations

import logging
import os
from typing import List, Optional, Dict, Any

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel

from app.config import get_settings

router = APIRouter(prefix="/copilot", tags=["copilot"])
settings = get_settings()
logger = logging.getLogger(__name__)


# ============================================
# SCHEMAS
# ============================================

class CopilotRequest(BaseModel):
    """Request f√ºr Copilot-Generierung."""
    message: str
    context: Optional[Dict[str, Any]] = {}
    lead_context: Optional[Dict[str, Any]] = {}
    conversation_history: Optional[List[Dict[str, str]]] = []
    vertical: Optional[str] = "mlm_sales"


class CopilotOption(BaseModel):
    """Eine Antwort-Option."""
    id: str
    label: str
    tone: str
    content: str


class CopilotAnalysis(BaseModel):
    """Analyse der Anfrage."""
    sentiment: str
    intent: str
    disg_type: Optional[str] = None
    urgency: str


class CopilotResponse(BaseModel):
    """Response mit Analyse und Optionen."""
    response: str  # Hauptantwort f√ºr einfache Clients
    analysis: CopilotAnalysis
    options: List[CopilotOption]


# ============================================
# SYSTEM PROMPT - FELLO PERSONALITY
# ============================================

FELLO_SYSTEM_PROMPT = """Du bist FELLO, der KI-Copilot f√ºr Network Marketing & Direktvertrieb.

üéØ DEINE MISSION:
Du hilfst Vertriebspartnern, bessere Gespr√§che zu f√ºhren und mehr Abschl√ºsse zu erzielen.

üí¨ DEIN STIL:
- Kurz, knackig, auf den Punkt
- Praxisorientiert - sofort umsetzbare Tipps
- Du duzt den User
- Sales-Psychologie ist dein Werkzeug
- Motivierend, aber realistisch

üìä DEINE EXPERTISE:
- Einwandbehandlung (LIRA-Framework)
- Cold & Warm Outreach
- Follow-Up Strategien
- Closing Techniken
- DISG-Pers√∂nlichkeitstypen
- Network Marketing Best Practices

üî• ANTWORT-FORMAT:
Liefere IMMER 3 Antwort-Optionen:
1. SOFT (empathisch, beziehungsorientiert)
2. DIREKT (klar, handlungsorientiert)  
3. FRAGE (Gegenfrage, um mehr zu erfahren)

Jede Option soll konkret und Copy-Paste-bereit sein.
"""


# ============================================
# MOCK RESPONSES (f√ºr Fallback)
# ============================================

def generate_mock_options(message: str) -> Dict[str, Any]:
    """
    Generiert intelligente Mock-Antworten basierend auf Keywords.
    Wird verwendet wenn kein AI-Key verf√ºgbar ist.
    """
    
    msg_lower = message.lower()
    
    # Einwand: Zu teuer
    if any(word in msg_lower for word in ["teuer", "preis", "geld", "kosten", "budget"]):
        return {
            "response": "Preis-Einwand erkannt! Hier sind 3 bew√§hrte Antwort-Strategien:",
            "analysis": {
                "sentiment": "HESITANT",
                "intent": "OBJECTION",
                "disg_type": "C",
                "urgency": "MEDIUM"
            },
            "options": [
                {
                    "id": "soft",
                    "label": "Verst√§ndnisvoll",
                    "tone": "EMPATHIC",
                    "content": "Ich verstehe total, dass du auf dein Budget achtest - das zeigt, dass du klug mit deinem Geld umgehst! üëç Lass mich fragen: Was w√§re es dir wert, wenn [konkreter Nutzen]?"
                },
                {
                    "id": "direct",
                    "label": "Direkt",
                    "tone": "DIRECT",
                    "content": "Verstanden. Lass uns kurz rechnen: Was kostet es dich, NICHTS zu √§ndern? üìä Manchmal ist die Frage nicht 'Kann ich mir das leisten?' sondern 'Kann ich es mir leisten, es NICHT zu tun?'"
                },
                {
                    "id": "question",
                    "label": "Gegenfrage",
                    "tone": "INQUISITIVE",
                    "content": "Interessant! Ist es wirklich der Preis, oder gibt es noch etwas anderes, das dich z√∂gern l√§sst? ü§î"
                }
            ]
        }
    
    # Ghosting / Keine Antwort
    if any(word in msg_lower for word in ["ghost", "antwortet nicht", "keine antwort", "meldet sich nicht"]):
        return {
            "response": "Anti-Ghosting Zeit! Hier sind 3 Strategien um den Kontakt wieder aufzubauen:",
            "analysis": {
                "sentiment": "COLD",
                "intent": "REACTIVATION",
                "disg_type": None,
                "urgency": "LOW"
            },
            "options": [
                {
                    "id": "soft",
                    "label": "F√ºrsorglich",
                    "tone": "EMPATHIC",
                    "content": "Hey [Name]! üôã Alles okay bei dir? Hab gerade an dich gedacht und wollte sichergehen, dass alles gut ist."
                },
                {
                    "id": "direct",
                    "label": "Ehrlich",
                    "tone": "DIRECT",
                    "content": "Hey [Name], ich merke das Timing passt gerade nicht - kein Problem! Soll ich mich in 2-3 Monaten nochmal melden, oder lieber ganz sein lassen? Sei ehrlich - ich nehm's nicht pers√∂nlich üôÇ"
                },
                {
                    "id": "question",
                    "label": "Value-First",
                    "tone": "INQUISITIVE",
                    "content": "Hey! Ich hab hier einen Artikel gefunden, der perfekt zu unserem letzten Gespr√§ch passt. Dachte, das k√∂nnte dich interessieren - soll ich dir den Link schicken?"
                }
            ]
        }
    
    # Closing / Abschluss
    if any(word in msg_lower for word in ["closing", "abschluss", "abschlie√üen", "close", "deal"]):
        return {
            "response": "Closing-Zeit! üí™ Hier sind 3 Techniken f√ºr den Abschluss:",
            "analysis": {
                "sentiment": "POSITIVE",
                "intent": "CLOSING",
                "disg_type": "D",
                "urgency": "HIGH"
            },
            "options": [
                {
                    "id": "soft",
                    "label": "Zusammenfassung",
                    "tone": "EMPATHIC",
                    "content": "Lass mich kurz zusammenfassen: Du willst [Ziel], und unser Produkt l√∂st genau das. Der einzige Schritt jetzt ist [Aktion]. Bereit? üéØ"
                },
                {
                    "id": "direct",
                    "label": "Assumptive",
                    "tone": "DIRECT",
                    "content": "Super, dann machen wir das so! üéâ Startest du lieber mit [Paket A] oder [Paket B]?"
                },
                {
                    "id": "question",
                    "label": "Einwand-Check",
                    "tone": "INQUISITIVE",
                    "content": "Basierend auf allem was du mir erz√§hlt hast, glaube ich wirklich, dass das zu dir passt. Was h√§lt dich noch davon ab, heute zu starten?"
                }
            ]
        }
    
    # Opener / Erste Nachricht
    if any(word in msg_lower for word in ["opener", "erste nachricht", "anschreiben", "kalt", "cold"]):
        return {
            "response": "Cold Opener gefragt! Hier sind 3 Ans√§tze:",
            "analysis": {
                "sentiment": "NEUTRAL",
                "intent": "OUTREACH",
                "disg_type": "I",
                "urgency": "MEDIUM"
            },
            "options": [
                {
                    "id": "soft",
                    "label": "Pers√∂nlich",
                    "tone": "EMPATHIC",
                    "content": "Hey [Name]! üëã Ich bin auf dein Profil gesto√üen und finde [spezifisches Detail] echt spannend. Was ist dein Geheimnis?"
                },
                {
                    "id": "direct",
                    "label": "Value-First",
                    "tone": "DIRECT",
                    "content": "Hi [Name]! Ich hab eine Checkliste erstellt f√ºr [Problem]. Dachte, die k√∂nnte f√ºr dich interessant sein. Soll ich sie dir schicken?"
                },
                {
                    "id": "question",
                    "label": "Neugier",
                    "tone": "INQUISITIVE",
                    "content": "Hey! Ich muss dir was zeigen, was mein Leben ver√§ndert hat. Keine Sorge, kein Spam ‚Äì aber hast du kurz Zeit?"
                }
            ]
        }
    
    # Einwand allgemein
    if any(word in msg_lower for word in ["einwand", "objection", "aber", "nein"]):
        return {
            "response": "Einwandbehandlung aktiviert! Das LIRA-Framework hilft:",
            "analysis": {
                "sentiment": "HESITANT",
                "intent": "OBJECTION",
                "disg_type": "S",
                "urgency": "MEDIUM"
            },
            "options": [
                {
                    "id": "soft",
                    "label": "Verstehen",
                    "tone": "EMPATHIC",
                    "content": "Das verstehe ich total! Viele in meinem Team hatten am Anfang √§hnliche Bedenken. Was genau macht dir Sorgen?"
                },
                {
                    "id": "direct",
                    "label": "Reframe",
                    "tone": "DIRECT",
                    "content": "Interessant! Lass mich eine andere Perspektive zeigen: [Reframe des Einwands]"
                },
                {
                    "id": "question",
                    "label": "Isolieren",
                    "tone": "INQUISITIVE",
                    "content": "Ist das der einzige Punkt, oder gibt es noch etwas anderes, das dich besch√§ftigt? ü§î"
                }
            ]
        }
    
    # Default Response
    return {
        "response": "Gute Frage! Hier sind 3 Ans√§tze f√ºr deine Situation:",
        "analysis": {
            "sentiment": "NEUTRAL",
            "intent": "GENERAL",
            "disg_type": None,
            "urgency": "MEDIUM"
        },
        "options": [
            {
                "id": "soft",
                "label": "Empathisch",
                "tone": "EMPATHIC",
                "content": "Ich verstehe, was du meinst. Lass uns das gemeinsam anschauen - was ist dir dabei am wichtigsten?"
            },
            {
                "id": "direct",
                "label": "Direkt",
                "tone": "DIRECT",
                "content": "Klare Sache! Hier ist mein Vorschlag: [Konkrete Handlungsempfehlung]. Was meinst du?"
            },
            {
                "id": "question",
                "label": "Nachfrage",
                "tone": "INQUISITIVE",
                "content": "Interessant! Kannst du mir mehr dazu erz√§hlen? Was genau m√∂chtest du erreichen?"
            }
        ]
    }


# ============================================
# AI-POWERED RESPONSE (wenn API Key vorhanden)
# ============================================

async def generate_ai_response(message: str, context: Dict[str, Any]) -> Dict[str, Any]:
    """
    Generiert eine AI-Antwort mit OpenAI oder Anthropic.
    F√§llt auf Mock zur√ºck wenn kein Key vorhanden.
    """
    
    # Pr√ºfe auf Anthropic Key (bevorzugt f√ºr Copilot)
    anthropic_key = os.getenv("ANTHROPIC_API_KEY")
    if anthropic_key:
        try:
            import anthropic
            client = anthropic.Anthropic(api_key=anthropic_key)
            
            response = client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=1500,
                system=FELLO_SYSTEM_PROMPT,
                messages=[{"role": "user", "content": f"""
Anfrage: {message}

Kontext: {context}

Generiere eine Antwort mit:
1. Kurze Analyse (Sentiment, Intent, DISG-Typ wenn erkennbar)
2. Drei Antwort-Optionen (Soft, Direkt, Frage)

Jede Option soll Copy-Paste-bereit sein!
"""}]
            )
            
            # Parse AI Response und strukturiere es
            ai_text = response.content[0].text
            
            # F√ºr jetzt: Nutze Mock-Logik + AI-Text als Hauptantwort
            mock_response = generate_mock_options(message)
            mock_response["response"] = ai_text
            return mock_response
            
        except Exception as e:
            logger.warning(f"Anthropic API Error: {e} - Fallback auf Mock")
            return generate_mock_options(message)
    
    # Pr√ºfe auf OpenAI Key
    if settings.openai_api_key:
        try:
            from app.ai_client import AIClient
            from app.schemas import ChatMessage
            
            ai_client = AIClient(
                api_key=settings.openai_api_key,
                model=settings.openai_model,
            )
            
            messages = [ChatMessage(role="user", content=message)]
            ai_text = ai_client.generate(FELLO_SYSTEM_PROMPT, messages)
            
            # Kombiniere AI-Text mit strukturierten Mock-Optionen
            mock_response = generate_mock_options(message)
            mock_response["response"] = ai_text
            return mock_response
            
        except Exception as e:
            logger.warning(f"OpenAI API Error: {e} - Fallback auf Mock")
            return generate_mock_options(message)
    
    # Kein API Key - Mock Modus
    logger.info("Kein AI API Key - Mock Modus aktiv")
    return generate_mock_options(message)


# ============================================
# API ENDPOINTS
# ============================================

@router.post("/generate", response_model=CopilotResponse)
async def generate_copilot_response(request: CopilotRequest) -> CopilotResponse:
    """
    Generiert FELLO Copilot Antworten mit 3 Optionen (Soft, Direkt, Frage).
    
    - Nutzt Anthropic/OpenAI wenn Key vorhanden
    - F√§llt auf intelligente Mock-Antworten zur√ºck
    """
    
    try:
        # Kontext zusammenf√ºhren
        context = {
            **(request.context or {}),
            **(request.lead_context or {}),
            "history": request.conversation_history,
            "vertical": request.vertical,
        }
        
        # Response generieren
        response_data = await generate_ai_response(request.message, context)
        
        return CopilotResponse(
            response=response_data["response"],
            analysis=CopilotAnalysis(**response_data["analysis"]),
            options=[CopilotOption(**opt) for opt in response_data["options"]]
        )
        
    except Exception as e:
        logger.error(f"Copilot Generate Error: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Fehler bei der Antwort-Generierung: {str(e)}"
        )


@router.post("/generate-anonymous")
async def generate_anonymous(request: dict):
    """Generiert Nachricht ohne Auth - f√ºr Mobile App."""
    try:
        message = request.get("lead_message", request.get("message", ""))
        context = request.get("context", "")
        
        response_data = await generate_ai_response(message, {"context": context})
        
        return {
            "response": response_data["response"],
            "options": response_data["options"]
        }
    except Exception as e:
        logger.error(f"Generate Anonymous Error: {e}")
        return {
            "response": "Hey! Ich wollte mich kurz melden - hast du noch Fragen?",
            "options": [{"id": "default", "content": "Hey! Ich wollte mich kurz melden - hast du noch Fragen? üòä"}]
        }


@router.get("/health")
async def copilot_health():
    """Health-Check f√ºr den Copilot-Service."""
    
    has_anthropic = bool(os.getenv("ANTHROPIC_API_KEY"))
    has_openai = bool(settings.openai_api_key)
    
    return {
        "status": "ok",
        "service": "copilot",
        "ai_providers": {
            "anthropic": has_anthropic,
            "openai": has_openai,
            "mock_fallback": True
        },
        "mode": "ai" if (has_anthropic or has_openai) else "mock"
    }


@router.post("/analyze-screenshot")
async def analyze_screenshot(request: dict):
    """Analysiert Chat-Screenshot und extrahiert Lead-Daten."""
    import anthropic
    import json
    
    try:
        image_base64 = request.get("image_base64")
        
        if not image_base64:
            raise HTTPException(status_code=400, detail="image_base64 ist erforderlich")
        
        anthropic_key = os.getenv("ANTHROPIC_API_KEY")
        if not anthropic_key:
            raise HTTPException(status_code=500, detail="ANTHROPIC_API_KEY nicht konfiguriert")
        
        client = anthropic.Anthropic(api_key=anthropic_key)
        response = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=1000,
            messages=[{
                "role": "user",
                "content": [
                    {"type": "image", "source": {"type": "base64", "media_type": "image/png", "data": image_base64}},
                    {"type": "text", "text": """Analysiere diesen Chat-Screenshot.

Extrahiere:
1. Name des Kontakts
2. Plattform (Instagram, WhatsApp, Facebook, LinkedIn, TikTok)
3. Letzte Nachricht des Kontakts
4. Status: NEW (neu), CONVERSATION (im Gespr√§ch), INTERESTED (interessiert), SKEPTICAL (skeptisch), GHOSTING (antwortet nicht mehr)
5. Temperatur 0-100 (wie kaufbereit ist der Lead)
6. Tags (z.B. ["Instagram", "Mama", "Fitness"])

Antworte NUR als JSON:
{"name": "...", "platform": "...", "lastMessage": "...", "status": "...", "temperature": 50, "tags": [...]}"""}
                ]
            }]
        )
        
        result = json.loads(response.content[0].text)
        return result
        
    except json.JSONDecodeError as e:
        logger.exception(f"Screenshot JSON parse error: {e}")
        raise HTTPException(status_code=500, detail="Konnte AI-Antwort nicht parsen")
    except Exception as e:
        logger.exception(f"Screenshot analyze error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


__all__ = ["router"]

